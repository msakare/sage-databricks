name: Databricks job migration

on:
  
  workflow_dispatch:
    inputs:
      source_env:
        type: choice
        description: "Select source environment"
        required: true
        options:
        - Dev
        - Test
        - Prod
      target_env:
        description: "Select target environment"
        required: true
        type: choice
        options: ["Dev", "Test", "Prod"]
      # job_id:
      #     description: "Select a job ID"
      #     required: true
      #     type: choice
      #     options: ${{ steps.job_ids.outputs.job_ids }}
        
        
jobs:
  databricks_migration:
    runs-on: ubuntu-latest

    env:
      SOURCE_ENV: ${{ github.event.inputs.source_env }}
      TARGET_ENV: ${{ github.event.inputs.target_env }}
      JOB_ID: ${{ github.event.inputs.job_id }}
      DATABRICKS_API_TOKEN: ${{secrets.DATABRICKS_API_TOKEN}}
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: setup-ghcli
        # You may pin to the exact commit or the version.
        # uses: twildber/setup-ghcli@89d4a02bf60883b0b609bba486acafabd82066bf
        uses: twildber/setup-ghcli@v0.8.0
        with:
          # The version to use. Example: 2.28.0
          version: 2.28.0
        
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install requests

      - name: Install fzf
        run: sudo apt-get update && sudo apt-get install -y fzf

  
      # - name: Call Databricks API and Publish Artifacts
      #   run: |
      #     python .github/workflows/apicall.py 
      - name: Call Databricks API and Extract Job IDs
        id: job_ids
        run: |
          job_ids=$(python .github/workflows/apicall.py)
          echo "::set-output name=job_ids::${job_ids}"

      - name: Get Databricks Job List
        run: |
          # Use the selected source environment and Databricks API token to call the Get Jobs List API
          # Store the job list in a file or environment variable for later use
          python .github/workflows/get_job_list.py | python .github/workflows/extract_job_ids.py
      
          # Install fzf
          sudo apt-get update && sudo apt-get install -y fzf
      
          # Allow the user to select a job ID (using fzf)
          selected_job_id=$(echo "$job_ids" | fzf) # Replace with your preferred selection method
      
          # Store the selected job ID as a GitHub Actions environment variable for later steps
          echo "SELECTED_JOB_ID=$selected_job_id" >> $GITHUB_ENV




      - name: list Job ID
        id: list_job_id
        run: echo "Selected job ID is ${{ steps.job_ids.outputs.job_ids }}"
        env:
          job_ids: ${{ steps.job_ids.outputs.job_ids }}
        shell: bash

      - name: Fetch Job Details
        id: fetch_job_details
        run: |
            job_details=$(python .github/workflows/fetch_job_details.py)
            echo "::set-output name=job_details::${job_details}"


      - name: Display Job Details
        run: |
          job_details="${{ steps.fetch_job_details.outputs.job_details }}"
          echo "Job ID Details:"
          echo "$job_details"


      # - name: Trigger Slash Command
      #   uses: peter-evans/slash-command-dispatch@v2
      #   with:
      #     token: ${{secrets.PAT_TOKEN}}
      #     issue-type: select-job
      #     job_ids: ${{ steps.job_ids.outputs.job_ids }}  


      




  # select_and_run_job:
  #   needs: databricks_migration
  #   runs-on: ubuntu-latest

  #   steps:



      # - name: Select Job ID
      #   id: select_job_id
      #   run: |
      #     job_ids="${{ steps.job_ids.outputs.job_ids }}"
      #     echo "Available Job IDs: $job_ids"
      #     echo "Please enter the Job ID you want to use:"
      #     read selected_job_id
      #     echo "::set-output name=selected_job_id::${selected_job_id}"
      #   shell: bash

      # - name: Run Python Script with Selected Job ID
      #   run: |
      #     selected_job_id="${{ steps.select_job_id.outputs.selected_job_id }}"
      #     databricks_api_token = "dapic100eda776087528cd6a82f7ca84914a"
      #     url="https://sagerx-aws-devtest-comm.cloud.databricks.com/api/2.1/jobs/get?job_id=$selected_job_id"
      #     payload={}
      #     headers = {
      #       'Authorization': f'Bearer {databricks_api_token}'
      #     }
      #     response = requests.request("GET", url, headers=headers, data=payload)
      #     echo $response.text



      # - name: Display Job IDs
      #   run: |
      #     echo "Available Job IDs:"
      #     echo "${{ steps.job_ids.outputs.job_ids }}"  
      # ... (previous steps) ...

      # - name: Capture Selected Job ID
      #   id: select_job_id
      #   run: |
      #     job_ids="${{ steps.job_ids.outputs.job_ids }}"
      #     echo "::set-output name=selected_job_id::${job_ids}"
      #   shell: bash
      #   env:
      #     job_ids: ${{ steps.job_ids.outputs.job_ids }}

      # - name: Generate List of Job IDs
      #   id: generate_job_ids
      #   run: |
      #     # Replace this with your logic to generate the list of job IDs
      #     # For example, you can query a data source or use previous workflow outputs.
      #     job_ids="job_id1,job_id2,job_id3"  # Replace with your actual list
      #     echo "::set-output name=job_ids::${job_ids}"

      # - name: Workflow Dispatch
      #   id: workflow_dispatch
      #   uses: softprops/action-gh-release@v1
      #   with:
      #     ref: dev_jobs
      #     workflow: Second Workflow
      #     inputs: |
      #       {
      #         "job_ids": {
      #           "description": "Select a job ID",
      #           "required": true,
      #           "type": "choice",
      #           "options": "${{ steps.generate_job_ids.outputs.job_ids }}"
      #         }
      #       }

      # - name: Trigger Second Workflow
      #   run: |
      #     selected_job_id="${{ steps.select_job_id.outputs.selected_job_id }}"
      #     echo "Selected Job ID: $selected_job_id"
      #     echo "Triggering second workflow..."
      #     export GH_TOKEN="${{ secrets.GITHUB_TOKEN }}"
      #     gh workflow run main.yaml --ref main -F job_ids="${selected_job_id}"

























      # - name: Publish Response as Artifact
      #   uses: actions/upload-artifact@v2
      #   with:
      #     name: databricks-api-response
      #     path: api_response.json

      # - name: Download and Process API Response
      #   uses: actions/download-artifact@v2
      #   with:
      #     name: databricks-api-response
      #     path: .

      # - name: Set JOB_ID from Artifact
      #   id: download
      #   run: python .github/workflows/readjsonfile.py

      # - name: Fetch Job Details
      #   run: python .github/workflows/fetch_job_details.py ${{ env.JOB_ID }}
      #   env:
      #     DATABRICKS_API_TOKEN: "dapic100eda776087528cd6a82f7ca84914a"


      # - name: Create Dropdown
      #   id: dropdown
      #   run: |
      #     job_ids="${{ steps.download.outputs.job_ids }}"
      #     echo "::set-output name=dropdown::${job_ids}"

      # - name: Display Dropdown
      #   run: |
      #     echo "Job IDs: ${{ steps.dropdown.outputs.dropdown }}"



        
      # - name: Fetch Job Details
      #   run: python .github/workflows/fetch_job_details.py 



     # - name: Set JOB_ID from Artifact
    #   run: echo "JOB_ID=${{ steps.download.outputs.job_id }}" >> $GITHUB_ENV

              # - name: Select Databricks Job ID
    #   run: |
     #     # Python script to prompt the user to select a job ID and list its details
     #     python .github/workflows/select_job_id.py










